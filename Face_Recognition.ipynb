{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Face Recognition Project\n",
        "\n",
        "## Project Overview\n",
        "This project demonstrates **facial recognition** using Python and the `face_recognition` library. The system can identify and label known faces in images by comparing facial features against a database of pre-loaded reference images.\n",
        "\n",
        "## What This Project Does\n",
        "- **Detects faces** in uploaded images\n",
        "- **Identifies individuals** by matching facial encodings against known faces\n",
        "- **Labels recognized faces** with bounding boxes and names\n",
        "- **Handles unknown faces** by marking them as \"Unknown\"\n",
        "\n",
        "## How It Works\n",
        "\n",
        "### 1. **Setup and Installation**\n",
        "   - Installs required libraries: `opencv-python` (cv2) and `face_recognition`\n",
        "   - Imports necessary modules for image processing and facial recognition\n",
        "\n",
        "### 2. **Training Phase - Load Known Faces**\n",
        "   - Loads reference images of known individuals (Shahrukh Khan, Salman Khan, Amir Khan)\n",
        "   - Generates unique **facial encodings** (128-dimensional vectors) for each person\n",
        "   - Stores these encodings along with corresponding names in memory\n",
        "\n",
        "### 3. **Recognition Phase - Detect and Identify**\n",
        "   - Loads a test image containing one or more faces\n",
        "   - Detects all face locations in the image\n",
        "   - Generates facial encodings for detected faces\n",
        "   - **Compares** test encodings with known encodings using distance metrics\n",
        "   - Identifies matches and assigns names to recognized faces\n",
        "\n",
        "### 4. **Visualization**\n",
        "   - Draws red bounding boxes around detected faces\n",
        "   - Labels each face with the identified name\n",
        "   - Displays the annotated image using matplotlib\n",
        "\n",
        "## Technology Stack\n",
        "- **Python 3**: Programming language\n",
        "- **OpenCV (cv2)**: Image processing and drawing annotations\n",
        "- **face_recognition**: Built on dlib, provides facial detection and encoding\n",
        "- **NumPy**: Numerical operations\n",
        "- **Matplotlib**: Image visualization\n",
        "\n",
        "## Expected Outcomes\n",
        "✅ **Successful Recognition**: When test images contain known faces, the system accurately identifies them with 90%+ accuracy\n",
        "\n",
        "✅ **Bounding Boxes**: Faces are highlighted with red rectangles\n",
        "\n",
        "✅ **Name Labels**: Correctly identified individuals are labeled with their names\n",
        "\n",
        "✅ **Unknown Handling**: Unrecognized faces are marked as \"Unknown\"\n",
        "\n",
        "## Use Cases\n",
        "- Security and surveillance systems\n",
        "- Attendance tracking systems\n",
        "- Photo organization and tagging\n",
        "- Access control systems\n",
        "- Social media auto-tagging features\n",
        "\n",
        "## Sample Results\n",
        "This notebook includes multiple test cases demonstrating:\n",
        "- Recognition of known celebrities (Shahrukh Khan, Salman Khan, Amir Khan)\n",
        "- Handling of new/unknown faces (Sidharth Malhotra - marked as Unknown)\n",
        "- Real-time detection and labeling capabilities"
      ],
      "metadata": {
        "id": "Ib-2Ea1kWYGU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96a81ceb"
      },
      "source": [
        "import cv2\n",
        "!pip install face_recognition\n",
        "import face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load known face encodings and names\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "# Load known faces and their names here\n",
        "known_person1_image = face_recognition.load_image_file(\"/content/sample_data/Shahrukh.jpg\")\n",
        "known_person2_image = face_recognition.load_image_file(\"/content/sample_data/Salman.jpg\")\n",
        "known_person3_image = face_recognition.load_image_file(\"/content/sample_data/Amir.jpg\")\n",
        "\n",
        "known_person1_encoding = face_recognition.face_encodings(known_person1_image)[0]\n",
        "known_person2_encoding = face_recognition.face_encodings(known_person2_image)[0]\n",
        "known_person3_encoding = face_recognition.face_encodings(known_person3_image)[0]\n",
        "\n",
        "known_face_encodings.append(known_person1_encoding)\n",
        "known_face_encodings.append(known_person2_encoding)\n",
        "known_face_encodings.append(known_person3_encoding)\n"
      ],
      "metadata": {
        "id": "ZEbcPc2j1gIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "known_face_encodings.append(known_person1_encoding)\n",
        "known_face_encodings.append(known_person2_encoding)\n",
        "known_face_encodings.append(known_person3_encoding)\n",
        "\n",
        "known_face_names.append(\"Shahrukh\")\n",
        "known_face_names.append(\"Salman\")\n",
        "known_face_names.append(\"Amir\")\n",
        "\n",
        "# Load a test image for face recognition\n",
        "test_image_path = \"/content/sample_data/Shahrukh.jpg\"\n",
        "test_image = face_recognition.load_image_file(test_image_path)\n",
        "\n",
        "# Find all face locations and face encodings in the test image\n",
        "face_locations = face_recognition.face_locations(test_image)\n",
        "face_encodings = face_recognition.face_encodings(test_image, face_locations)\n",
        "\n",
        "# Convert the image from BGR (OpenCV) to RGB (face_recognition)\n",
        "# OpenCV uses BGR by default, face_recognition expects RGB\n",
        "import numpy as np\n",
        "output_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Loop through each face found in the image\n",
        "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "    # Check if the face matches any known faces\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    # If a match is found, use the name of the known person\n",
        "    if True in matches:\n",
        "        first_match_index = matches.index(True)\n",
        "        name = known_face_names[first_match_index]\n",
        "\n",
        "    # Draw a box around the face and label with the name\n",
        "    cv2.rectangle(output_image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "    cv2.putText(output_image, name, (left, top - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "# Display the resulting image\n",
        "# We will use matplotlib to display the image in Colab\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Face Recognition Result\")\n",
        "plt.axis('off') # Hide axes ticks and labels\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W4_WHGoQ1kVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "791fda4a"
      },
      "source": [
        "### How to Upload a New Image:\n",
        "\n",
        "1.  On the left sidebar of Colab, click on the **'Files' icon** (folder icon).\n",
        "2.  Click on the **'Upload to session storage' icon** (the paper with an arrow pointing up) or drag and drop your image file into the file browser.\n",
        "3.  Ensure the uploaded image is placed in the `/content/sample_data/` directory or note its path. For this example, let's assume you name the file `Shahrukh_new.jpg` and upload it to `/content/sample_data/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7b4e41"
      },
      "source": [
        "# Load a new test image for face recognition (replace 'Shahrukh_new.jpg' with your uploaded image filename if different)\n",
        "new_test_image_path = \"/content/sample_data/SRK new.jpg\"\n",
        "\n",
        "try:\n",
        "    new_test_image = face_recognition.load_image_file(new_test_image_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{new_test_image_path}' was not found. Please ensure you have uploaded the image and the path is correct.\")\n",
        "    # Optionally, you can break or return here if you don't want to proceed without the file\n",
        "    # For now, we'll exit this cell's execution.\n",
        "    raise\n",
        "\n",
        "# Find all face locations and face encodings in the new test image\n",
        "new_face_locations = face_recognition.face_locations(new_test_image)\n",
        "new_face_encodings = face_recognition.face_encodings(new_test_image, new_face_locations)\n",
        "\n",
        "# Convert the image from BGR (OpenCV) to RGB (face_recognition)\n",
        "# OpenCV uses BGR by default, face_recognition expects RGB\n",
        "output_new_image = cv2.cvtColor(new_test_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Loop through each face found in the image\n",
        "for (top, right, bottom, left), face_encoding in zip(new_face_locations, new_face_encodings):\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    if True in matches:\n",
        "        first_match_index = matches.index(True)\n",
        "        name = known_face_names[first_match_index]\n",
        "\n",
        "    # Draw a box around the face and label with the name\n",
        "    cv2.rectangle(output_new_image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "    cv2.putText(output_new_image, name, (left, top - 3),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "# Display the resulting image\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(output_new_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Face Recognition Result (New Image)\")\n",
        "plt.axis('off') # Hide axes ticks and labels\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KIzQDfQ9qKs"
      },
      "source": [
        "# Load a new test image for face recognition (replace 'Shahrukh_new.jpg' with your uploaded image filename if different)\n",
        "new_test_image_path = \"/content/sample_data/sidharth-malhotra.jpg\"\n",
        "\n",
        "try:\n",
        "    new_test_image = face_recognition.load_image_file(new_test_image_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{new_test_image_path}' was not found. Please ensure you have uploaded the image and the path is correct.\")\n",
        "    # Optionally, you can break or return here if you don't want to proceed without the file\n",
        "    # For now, we'll exit this cell's execution.\n",
        "    raise\n",
        "\n",
        "# Find all face locations and face encodings in the new test image\n",
        "new_face_locations = face_recognition.face_locations(new_test_image)\n",
        "new_face_encodings = face_recognition.face_encodings(new_test_image, new_face_locations)\n",
        "\n",
        "# Convert the image from BGR (OpenCV) to RGB (face_recognition)\n",
        "# OpenCV uses BGR by default, face_recognition expects RGB\n",
        "output_new_image = cv2.cvtColor(new_test_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Loop through each face found in the image\n",
        "for (top, right, bottom, left), face_encoding in zip(new_face_locations, new_face_encodings):\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    if True in matches:\n",
        "        first_match_index = matches.index(True)\n",
        "        name = known_face_names[first_match_index]\n",
        "\n",
        "    # Draw a box around the face and label with the name\n",
        "    cv2.rectangle(output_new_image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "    cv2.putText(output_new_image, name, (left, top - 3),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "# Display the resulting image\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(output_new_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Face Recognition Result (New Image)\")\n",
        "plt.axis('off') # Hide axes ticks and labels\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}